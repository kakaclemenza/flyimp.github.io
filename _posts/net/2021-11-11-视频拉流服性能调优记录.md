---
layout: post
title: 视频拉流服性能调优记录
category: net
typora-root-url: ../..
---

## 基本信息采集

```shell
# 查看网卡设备丢包信息: 无
# 其他指令如:
#     ip -s -s link ls eno1
#     netstat -i
root@92f09276:/home/ops# cat /proc/net/dev
Inter-|   Receive                                                |  Transmit
 face |bytes    packets errs drop fifo frame compressed multicast|bytes    packets errs drop fifo colls carrier compressed
    lo: 834688115433 152863123    0    0    0     0          0         0 834688115433 152863123    0    0    0     0       0          0
  eth0: 270147829966 837934076    0    0    0     0          0         0 4567129070077 1463553770    0    0    0     0       0          0
# 查看Tcp和IP层有没有异常丢包信息: 无
# 其他指令如:
#    netstat -st: 查tcp层丢包
#    netstat -su: 查udp层丢包
root@92f09276:/home/ops# grep -E "^Tcp:|^Ip:" /proc/net/snmp | column -t
Ip:   Forwarding    DefaultTTL  InReceives  InHdrErrors  InAddrErrors  ForwDatagrams  InUnknownProtos  InDiscards   InDelivers  OutRequests  OutDiscards  OutNoRoutes  ReasmTimeout  ReasmReqds  ReasmOKs      ReasmFails  FragOKs  FragFails  FragCreates
Ip:   2             64          1060957435  0            0             0              0                0            1060042602  2239610410   73204912     0            0             0           0             0           0        2          0
Tcp:  RtoAlgorithm  RtoMin      RtoMax      MaxConn      ActiveOpens   PassiveOpens   AttemptFails     EstabResets  CurrEstab   InSegs       OutSegs      RetransSegs  InErrs        OutRsts     InCsumErrors
Tcp:  1             200         120000      -1           77012         109959         32019            62146        12          1059091763   4600159587   15535135     1820          19307       0
# 查看
root@92f09276:/home/ops# cat /proc/net/softnet_stat 
2538f146 00000000 00000060 00000000 00000000 00000000 00000000 00000000 00000000 0085de1a 00000000
02fc8c79 00000000 00000002 00000000 00000000 00000000 00000000 00000000 00000000 008ec4ee 00000000
03222a55 00000000 00000001 00000000 00000000 00000000 00000000 00000000 00000000 008005ee 00000000
02e6f82d 00000000 00000003 00000000 00000000 00000000 00000000 00000000 00000000 008215a4 00000000
067b630f 00000000 00000019 00000000 00000000 00000000 00000000 00000000 00000000 00000000 00000000
02ef024d 00000000 00000003 00000000 00000000 00000000 00000000 00000000 00000000 007bb138 00000000
029ee0cf 00000000 00000003 00000000 00000000 00000000 00000000 00000000 00000000 007cf1f0 00000000
030426ed 00000000 00000003 00000000 00000000 00000000 00000000 00000000 00000000 007386c1 00000000
# 查看网卡中断数=网卡队列数=1
root@92f09276:/home/ops# cat /proc/interrupts 
           CPU0       CPU1       CPU2       CPU3       CPU4       CPU5       CPU6       CPU7       
...
 27:   23978953          0          0          0   22143214          0          0          0   PCI-MSI 49153-edge      virtio0-input.0
 28:    3655875          0          0          0          0          0          0    3622019   PCI-MSI 49154-edge      virtio0-output.0
...
```

关于`/proc/net/softnet_stat` 的重要细节:

1. 每一行代表一个 `struct softnet_data` 变量。因为每个 CPU 只有一个该变量，所以每行
   其实代表一个 CPU
2. 每列用空格隔开，数值用 16 进制表示
3. 第一列 `sd->processed`，是处理的网络帧的数量。如果你使用了 ethernet bonding，
   那这个值会大于总的网络帧的数量，因为 ethernet bonding 驱动有时会触发网络数据被
   重新处理（re-processed）
4. 第二列，`sd->dropped`，是因为处理不过来而 drop 的网络帧数量。后面会展开这一话题
5. 第三列，`sd->time_squeeze`，前面介绍过了，由于 budget 或 time limit 用完而退出`net_rx_action` 循环的次数
6. 接下来的 5 列全是 0
7. 第九列，`sd->cpu_collision`，是为了发送包而获取锁的时候有冲突的次数
8. 第十列，`sd->received_rps`，是这个 CPU 被其他 CPU 唤醒去收包的次数
9. 最后一列，`flow_limit_count`，是达到 flow limit 的次数。flow limit 是 RPS 的特性，后面会稍微介绍一下

## 利用工具定位问题

### systemtap dropwatch.stp丢包定位工具

dropwatch.stp脚本, 可用于分析网络协议栈中丢包的确切位置. 确切的位置是使用symname或者symdata将内存地址翻译出来的函数信息, 翻译必须使用stap --all-modules选项以便加载所有的模块的符号表. 

```
--all-modules  
  Equivalent to specifying "-dkernel" and a "-d" for each kernel module that is  currently  loaded.   Cauion: this can make the probe modules considerably larger.  
```

脚本源码如下:

```
#!/usr/bin/stap  

############################################################  
# Dropwatch.stp  
# Author: Neil Horman <nhorman@redhat.com>  
# An example script to mimic the behavior of the dropwatch utility  
# http://fedorahosted.org/dropwatch  
############################################################  

# Array to hold the list of drop points we find  
global locations  

# Note when we turn the monitor on and off  
probe begin { printf("Monitoring for dropped packets\n") }  
probe end { printf("Stopping dropped packet monitor\n") }  

# increment a drop counter for every location we drop at  
probe kernel.trace("kfree_skb") { locations[$location] <<< 1 }  
// locations数组索引为$location, 记录kfree_skb被调用时的location参数信息, 即各模块符号表中的内存地址;  
// 使用symname()或者symdata()可以将地址转换成符号信息.  

# Every 5 seconds report our drop locations  
probe timer.sec(5)  
{  
  printf("\n")  
  foreach (l in locations-) {  
    #printf("%d packets dropped at %s\n",  
    #       @count(locations[l]), symname(l))  
    # 如果要输出模块信息以及函数在模块中的起始位置偏移量, 可以把symname替换成symdata来输出.  
    # 修改dropwatch.stp , 同时输出内存地址, 地址对应的符号表中的信息.  
    printf("%d packets dropped at %p, %s, %s\n",  
           @count(locations[l]), l, symname(l), symdata(l))  
  }  
  delete locations  
}  
// 每5秒输出一次  
// 按@count(locations[i]) 倒序输出  
// 输出包含符号名, 以及丢的包个数. 如果不加载模块, symname无法正确的翻译出函数名
```

如果无法使用symname和symdata转换, 手工从文件/boot/System.map-2.6.32-358.el6.x86_64中解读也是可以得到对应的函数的.  
/boot/System.map-2.6.32-358.el6.x86_64这个符号表记录了函数的起始地址和函数的对应关系.

如从$location以及符号表匹配函数 :   

```
6 packets dropped at 0xffffffff814a104a, tcp_v4_rcv, tcp_v4_rcv+0xaa/0x8d0 [kernel]  
```

0xffffffff814a104a这个地址**在ffffffff814a0fa0和ffffffff814a1870之间**, 所以也可以得到tcp_v4_rcv.

另一种方法是使用addr2line工具如下:

```shell
addr2line -e /usr/lib/debug/lib/modules/2.6.32-431.20.3.el6.mt20161028.x86_64/vmlinux ffffffff814a104a
```

### 利用perf工具

```shell
# 记录一会在`sleep 30`指令执行期间, skb:kfree_skb的调用情况; 输出文件在./perf.data
perf record -a -g -e skb:kfree_skb -- sleep 30

# 分析./perf.data, 输出报告
perf report -g graph,0 -i ./perf.data
```

### 视频转发服瓶颈分析

通过上面使用dropwatch.stp和perf工具, 输出如下

dropwatch.stp输出:

```shell
Thu Nov 11 03:45:52 2021
524820 packets dropped at kfree_skb_list
10 packets dropped at ip_rcv_finish
```

perf工具输出:

```shell
-    0.32%     0.32%  skbaddr=0xffff887af819d6e8 protocol=2048 location=0xffffffff9ccf7ea3
   - 0.32% 0
      - 0.21% 0x7fc6a38e5b50
           0x21
           0x7fc6a587a5dd
           entry_SYSCALL_64_after_swapgs
         - do_syscall_64
            - 0.10% SYSC_sendto
                 sock_sendmsg
                 tcp_sendmsg
                 __tcp_push_pending_frames
                 tcp_write_xmit
                 tcp_transmit_skb
                 ip_finish_output
                 ip_output
                 ip_finish_output
                 ip_finish_output2
                 __dev_queue_xmit
                 kfree_skb_list
                 kfree_skb
                 kfree_skb_list
                 kfree_skb
            - 0.10% sys_epoll_wait
                 default_wake_function
                 SYSC_sendto
                 sock_sendmsg
                 tcp_sendmsg
                 __tcp_push_pending_frames
                 tcp_write_xmit
                 tcp_transmit_skb
                 ip_finish_output
                 ip_output
                 ip_finish_output
                 ip_finish_output2
                 __dev_queue_xmit
                 kfree_skb_list
                 kfree_skb
                 kfree_skb_list
                 kfree_skb
```

这里可以定位到具体问题出现在`kfree_skb_list`函数的调用, 具体调用者是`__dev_queue_xmit`, 通过阅读这块的代码, 这里有使用qdisc算法进行发送流控. qdisc信息如下:

```shell
## qdisc队列信息, 流控算法是pfifo_fast
root@92f09276:/home/ops# tc -s qdisc
qdisc noqueue 0: dev lo root refcnt 2 
 Sent 0 bytes 0 pkt (dropped 0, overlimits 0 requeues 0) 
 backlog 0b 0p requeues 0 
qdisc pfifo_fast 0: dev eth0 root refcnt 2 bands 3 priomap  1 2 2 2 1 2 0 0 1 1 1 1 1 1 1 1
 Sent 5646572434561 bytes 3917500270 pkt (dropped 400940379, overlimits 0 requeues 429709) 
 backlog 0b 0p requeues 429709

root@92f09276:/home/ops# ethtool -g eth0
Ring parameters for eth0:
Pre-set maximums:
RX:             256
RX Mini:        0
RX Jumbo:       0
TX:             256
Current hardware settings:
RX:             256
RX Mini:        0
RX Jumbo:       0
TX:             256
```

这里可以看到qdisc使用的算法是pfifo_fast, 并且已经能看到统计丢包量很大. 通读qdisc实现代码, 发现qdisc入队受限于tx_queue_len的大小, 如果超过则直接调用qdisc_drop()丢弃包, 如下:

```c
// 源码位置: net/sched/sch_generic.c::pfifo_fast_enqueue()
static int pfifo_fast_enqueue(struct sk_buff *skb, struct Qdisc *qdisc,
                  struct sk_buff **to_free)
{
    if (qdisc->q.qlen < qdisc_dev(qdisc)->tx_queue_len) {
        int band = prio2band[skb->priority & TC_PRIO_MAX];
        struct pfifo_fast_priv *priv = qdisc_priv(qdisc);
        struct qdisc_skb_head *list = band2list(priv, band);

        priv->bitmap |= (1 << band);
        qdisc->q.qlen++;
        return __qdisc_enqueue_tail(skb, qdisc, list);
    }

    return qdisc_drop(skb, qdisc, to_free);
}
```

qdisc_drop处理如下, 就是将要丢弃的skb加入到to_free队列里:

```c
// 源码位置: include/net/sch_generic.h::qdisc_drop()
static inline void __qdisc_drop(struct sk_buff *skb, struct sk_buff **to_free)
{
    skb->next = *to_free;
    *to_free = skb;
}
```

而真正丢包的位置, 是在`net/core/dev.c::__dev_xmit_skb()`:

```c
static inline int __dev_xmit_skb(...) 
{
    ...
    rc = q->enqueue(skb, q, &to_free) & NET_XMIT_MASK;
    ...
    if (unlikely(to_free))
        kfree_skb_list(to_free);
}
```

由于`__dev_xmit_skb()`是内联函数, 被`__dev_queue_xmit()`调用, 所以在perf程序中堆栈显示调用`kfree_skb_list()`的是`__dev_queue_xmit()`.

到这里问题已经很清晰了, qdisc流控设置的队列长度过短, 当上层数据包发送过快时, qdisc队列满了就丢弃数据包. 这里通过配置加大队列长度可以缓解这个问题:

```shell
ip link set eth0 txqueuelen 10000
```
