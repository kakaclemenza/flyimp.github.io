---
layout: post
title: Todo
category: net
typora-root-url: ../..
---

[ T ] web ops操作link, port

[ T ] 实际线路切换测试

[ T ] 模块热更新问题

- 独立出ryu源码机制
- 模块依赖处理
- app加载机制和通知机制

[ T ] xxmysdn统计报告

[ T ] rule_maker策略优化. 如果大多走同一条线路或经过同一节点, 导致该线路带宽占用过大, 怎么办? 分情况解决

* 如果某个地区用户特别多, 按距离最近都选择了同一个接入点, 或指向同一个出口点
  => 接入点/出口点需要扩展多个机房, 并且增加带宽.
* 如果某条线路确实质量很好, 但是带宽限制较小, 那么有可能带宽上去导致丢包时切到另一条线路, 另一条线路很不好, 于是带宽下来之后又切回来.
  => 这种情况较不可能, 一般跳到另一条线路会足够稳定; 只要波动不超过阈值, 就会固定在另一条线路
* 某些线路/节点永远没被用上.
  => 这点可能性也较小, 按距离同运营商优先策略, 肯定能作为接入点而被用上.

[ T ] gre隧道的MTU设置问题: 由于gre为三层协议, 如果数据包大小超过underlay的MTU值, 会进行ip分片, 所以不会导致因MTU值丢包的问题, 大包只会增加分片的处理成本. 
​    从整个网络来看, 由于整个overlay网络只在接入点处会和实际网络MTU有因隧道封包导致的差异, 所以**增加的分片成本只在接入点**, 并不会影响整个网络, 因此MTU问题可以忽略. 

(2021-01-20) 这里要注意, 接入点p0网卡的MTU值必须减去gre隧道传输时的隧道包头. gre头最大20字节, ip头20字节. 则p0网卡的MTU值应该设置为1500-20-20=1460

[ T ] pingall测试的实现

- 思路一: 使用xxmygw框架, python脚本控制; 或使用shell脚本层实现, 依赖控制中心收集结果. 中心服收集; 使用udp_echo服务;
- 思路二: 使用Controller构造特殊的udp包, 并下发流表规则到最终目标ovs, 接收该特殊包上送Controller, Controller收到后计算延迟. => 难点: (1)特殊的udp包没有标准, 可能混淆正常业务包; (2)目标ovs如何识别不被中间ovs识别的有效包
- 思路三: 扩展Controller, 可以自定义与ovs的交互, 控制ovs发包

==> 选择解决方案: 思路一; (1)贴近于实际业务侧的观察结果; (2)对于ryu-ovs体系侵入性不大; (3)简单易实现

[ T ] 公网<->私网ip绑定xxmysdn_ip.lst内容统一化为json, xxmysdn可同步感知. => 相当于环境打包(容器化?), 方便部署.





(?) [不紧急]衡量某条path长时间的稳定性 => 数学: 数据稳定性分析

(?) [不紧急]xxmysdn对于偶尔高延迟问题没有检测到位(带宽占满导致), 无法感知

(?) [紧急]xxmysdn投入应用

(?) [不紧急]部署优化: 
* 同机房双机ovs节点思路: 确保从不同网段线路导入
* 控制节点三点自动选主思路(redis一致性问题)

(?) [计划中]xxmysdn控制器与xxmygw中心服功能代码融合

