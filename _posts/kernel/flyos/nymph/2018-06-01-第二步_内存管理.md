---
layout: post
title: 内存管理
category: flyos
tag: nymph
---



### 保护模式常识：

1. 现在应用程序运行的模式均处于保护模式。
2. 横向保护，又叫任务间保护，多任务操作系统中，一个任务不能破坏另一个任务的代码，这是通过内存分页以及不同任务的内存页映射到不同物理内存上来实现的。
3. 纵向保护，又叫任务内保护，系统代码与应用程序代码虽处于同一地址空间，但系统代码具有高优先级，应用程序代码处于低优先级，规定只能高优先级代码访问低优先级代码，这样杜绝用户代码破坏系统代码



### 内存地址概念

**逻辑地址** ：在进行C语言编程中，能读取变量地址值(&操作)，实际上这个值就是逻辑地址，也可以是通过malloc或是new调用返回的地址。该地址是相对于当前进程数据段的地址，不和绝对物理地址相干。只有在Intel实模式下，逻辑地址才和物理地址相等（因为实模式没有分段或分页机制,CPU不进行自动地址转换）。应用程序员仅需和逻辑地址打交道，而分段和分页机制对一般程序员来说是完全透明的，仅由系统编程人员涉及。应用程序员虽然自己能直接操作内存，那也只能在操作系统给你分配的内存段操作。一个逻辑地址，是由一个段标识符加上一个指定段内相对地址的偏移量，表示为 [段标识符：段内偏移量]。

**线性地址** ：是逻辑地址到物理地址变换之间的中间层。程序代码会产生逻辑地址，或说是段中的偏移地址，加上相应段的基地址就生成了一个线性地址。如果启用了分页机制，那么线性地址能再经变换以产生一个物理地址。若没有启用分页机制，那么线性地址直接就是物理地址。Intel 80386的线性地址空间容量为4G（2的32次方即32根地址总线寻址）。

**物理地址（Physical Address）** 是指出目前CPU外部地址总线上的寻址物理内存的地址信号，是地址变换的最终结果地址。如果启用了分页机制，那么线性地址会使用页目录和页表中的项变换成物理地址。如果没有启用分页机制，那么线性地址就直接成为物理地址了，比如在实模式下。



### 虚拟地址，线性地址，物理地址关系

对于保护模式下地址之间的转换，对程序员来说是透明的。那么物理内存通过内存管理机制是如何将虚拟地址转换为物理地址的呢？当程序中的指令访问某一个逻辑地址时，CPU首先会根据段寄存器的内容将虚拟地址转化为线性地址。如果CPU发现包含该线性地址的内存页不在物理内存中就会产生缺页异常，该异常的处理程序通过是操作系统的内存管理器例程。内存管理器得到异常报告后会根据异常的状态信息。特别是CR2寄存器中包含的线性地址，将需要的内存页加载到物理内存中。然后异常处理程序返回使处理器重新执行导致页错误异常的指令，这时所需要的内存页已经在物理内存中，所以便不会再导致页错误异常



### 物理内存情况获取

使用 e820 查看内存信息:   
1) e820 就是 BIOS 向 x86 架构（包括x86_64）上的操作系统引导程序提供物理内存信息的功能
2) 当请求BIOS中断号15H，并且置操作码AX=E820H的时候，BIOS就会向调用者报告可用的物理地址区间等信息，e820由此得名。



### Paging

#### what is MMU  
The MMU is a component of many computers that handles memory **translation**, memory **protection**, and other purposes specific to each architecture.  
MMU 是进行地址转换的控制单元. 它会根据不同的模式做不同的地址转换操作, 也就是说实模式和保护模式都是依赖它进行实现的. 实模式中, 其作用与旧CPU中的地址加法器相同.

#### PDE 和 PTE
On the x86, the MMU maps memory through a series of tables, two to be exact. They are the paging directory (PD), and the paging table (PT).  
* PDE(页目录表项)  
1) PDE 所指地址必须是 4K 对齐的, 因为其后 12-bit 是一些属性控制字段  
2) `S` 位控制页的大小是 4K 还是 4M. 4M 则需要 PSE 的开启, 并且 PDE 所指地址要变成 4M 对齐的, 后 22-bit 存放控制字段.

* PTE
1) PTE 和 PDE 一样, 只能指向 4K 对齐地址.

* 如何初始化
ref: https://wiki.osdev.org/Paging#Page_Directory 

#### PAE
This feature allows you to access up to **64 GiB** (2^36) of RAM. You can check for this feature using CPUID. Once checked, you can activate this feature by setting bit 5 in CR4. 
Once active, the CR3 register points to a table of 4 64-bit entries, each one pointing to a page directory made of 4096 bytes (like in normal paging), divided into 512 64-bit entries, each pointing to a 4096 byte page table, divided into 512 64bit page entries.


特点:
* PAE allows you to access more physical memory, which is usually 64GiB (in fact, this is implementation specific).
* A new data structure is added, the so called 'Page-Directory-Pointer-Table'(**PDPT**)
* An entry is now 8-byte-wide (Legacy: 4-byte), so the number of entries is halved to 512 (Legacy: 1024)
* If the CPU supports it you can use the NoExecute-bit

在长模式下(long mode), 分页机制使用 PAE.

#### IA-32E(nymph使用的模式)
PML4T是64位系统增加的一个结构，通过PML4T找到对应的PDPTE.   

64 位下的线性地址被分割为 6 个部分：

```
offset：12 位（Bit11 - Bit0），寻址 4K 空间
PTE index：9 位（Bit20 - Bit12），可索引 512 个 PT entries 表项
PDE index：9 位（Bit29 - Bit21），可索引 512 个 PDT entries 表项
PDPE index：9 位（Bit38 - Bit30），可索引 512 个 PDPT entries 表项
PML4E index：9 位（Bit47 - Bit39），可索引 512 个 PML4T entries 表项
Sign Extend：16 位（Bit63 - Bit48），符号扩展位
```
在 x64 体系里只实现了 48 位 virtual address，高 16 位被设计为符号扩展位，这样使得 48 位的 virtual address 在实现具有很大的弹性

ref: http://www.mouseos.com/arch/paging.html
ref: https://wiki.osdev.org/Setting_Up_Long_Mode

#### 分页的好处
* Virtual Address Spaces  
应用程序可以使用有相同的地址空间, 4G. 但是最终被放到真实的物理地址空间在哪里则有操作系统通过分页决定. 程序可以保持一致性, 却不会互相影响  
* Virtual Memory  
swap 的实现.  


### MM
#### 初始 1MB 的页

#### invlpg 指令
处理器使用TLB（Translation Lookaside Buffer）来缓存线性地址到物理地址的映射关系。实际的地址转换过程中，处理器首先根据线性地址查找TLB，如果未发现该线性地址到物理地址的映射关系（TLB miss），将根据页表中的映射关系填充TLB（TLB fill），然后再进行地址转换。  
invlpg 指令目的就是取消va对应物理页之间的关联，相当于刷新TLB，每次我们调整虚拟页和物理页之间的映射关系的时候，我们都要刷新TLB



### nymph中的内存初始化过程

**预分页阶段**

开启分页之前, 我们就需要把物理内存通过PML4T结构映射好, 以便在分页启动(分页启用实在进入64位long mode前, 通过操作寄存器统一启用的)后依然能正确的寻址. 这里nymph采用的方法是先映射低1M的内存,  PML4T存放在0x70000. 称测试的页表结构为**旧PML4T**

**实际分页阶段**

进入kernel_main()之后, 首先做的第一件事是将各种类型的中断处理设置好. 第二件事, 就是设置新的分页映射:

1. 检测整机可用内存, phsical_allocator::EarlyAllocate() 用于直接获取1M以上的可用内存块的最开始的地址, 该函数只会被paging::Init()调用一次, 且此时分配了的地址是不可以直接寻址使用的, 因为预分页阶段的旧PML4T没有映射1M以上的空间, 用于寻址会引发缺页中断! (应该和paging::Init()优化放在一起)
2. paging::Init() 通过 phsical_allocator::EarlyAllocate() 获得可用内存块的起始**物理地址**, 然后需要继续往旧PML4T中补充映射当前页; 所以nymph的做法就是, 每次获得一个新的物理页, 统一映射到旧PML4T中**pt[256]**进行初始化对应PML4T中的结构, 然后pt[256]中又会被放入另一个新的物理页. 如此, 只用一个虚拟页pt[256]的不断映射, 然后初始化, 就完成了对**新PML4T**的初始化过程. 新PML4T结构中最大可映射512GB的虚拟内存, 但k_kernel_virtual_size设置只映射到1G. 在我本机中该结构存放的物理起始地址正好为: 0x100000
3. 最后, 使用intel内嵌汇编, 更新了新PML4T结构的起始物理地址到cr3, 作为新页表结构地址.



### linux中内存分配过程

大块内存(以页为单位)使用Buddy算法

用户层申请的内存使用堆管理队列

内核层申请的内存使用slab分配器, 申请一整块内存作为对象池, 对一些频繁申请释放的对象放入对象池, 以后的申请和释放都直接从对象池, 避免内部碎片以及申请释放的开销. 



### nymph中内存分配过程

nymph的内存分配做法和linux基本相同, 不过nymph还没有实现slab分配器, 对于用户/内核内存分配均只能使用堆管理队列进行分配.

**内存页分配: Buddy算法**

buddy算法是对于内存页的分配算法. 在nymph中, buddy中对于内存页的组织并没有使用用户态内存分配器常用的树结构, 而是使用位图. 

位图结构占用的空间, 在virtual_allocator中是直接在程序静态存储区中分配的. 那么此时的程序栈空间在内存的什么位置呢?

通过程序的分析, virtual_allocator中位图结构data_bitmap_1等是放在.bss段中的, 让我们来印证下:

```shell
objdump -S -j .bss kernel.bin.o | grep data_bitmap
​```
0000000000033560 <_ZN12_GLOBAL__N_115data_bitmap_128E>:
0000000000033660 <_ZN12_GLOBAL__N_114data_bitmap_64E>:
0000000000033860 <_ZN12_GLOBAL__N_114data_bitmap_32E>:
0000000000033c60 <_ZN12_GLOBAL__N_114data_bitmap_16E>:
0000000000034460 <_ZN12_GLOBAL__N_113data_bitmap_8E>:
0000000000035460 <_ZN12_GLOBAL__N_113data_bitmap_4E>:
0000000000037450 <_ZN12_GLOBAL__N_113data_bitmap_2E>:
000000000003b420 <_ZN12_GLOBAL__N_113data_bitmap_1E>:
​```

# 这与通过gdb调试检查data_bitmap_1所在地址是一致的:
./kernel/gdb.sh
​```
...
(gdb) b virtual_allocator::Init
Breakpoint 2 at 0xdee3: file include/buddy_allocator.hpp, line 29.
(gdb) c
Continuing.

Breakpoint 2, virtual_allocator::Init () at src/virtual_allocator.cpp:57
57		g_allocator.SetMemoryRange(k_first_virtual_address, k_last_virtual_address);
(gdb) p &data_bitmap_1
$1 = (std::array<unsigned long, 4081ul> *) 0x3b420 <(anonymous namespace)::data_bitmap_1>
...
​```
```

这里需要注意, 初始的1M以下页表存放在0x70000内存位置, **.bss段应该保证不会覆盖到这片区域**. (栈段则在0x0~0x4000, 没有影响)

而对于physical_allocator中位图结构占用的空间, nymph中则是放到了1M以上的实际物理内存中; 这里视具体的内存情况, 也可以选择放在.bss段中.

* kernel/include/bitmap.hpp

  提供的是基础的位图操作

* kernel/include/buddy_allocator.hpp

  * 整个nymph的buddy分配器管理8级的内存, level从0到7

  * 判断最大块, 最大块为 128 * 4K/bit * 64bit = 32M; 如果需求过大, 无法分配, 否则, 如果要分配大于128个页的块, 则nymph中直接把level7的一整个word用完了, 这点需要优化下. 

    其他情况下, 都是根据查到分配页的大小查到level, 占用该level的一个bit, 并调用TokenDown()和TokenUp()设置其他level的占用

buddy分配使用举例: 要分配20个页的内存块

1. 由于20 > 16, 所以只能选择一个32个页的块, 所以需要在**level5**取一个FreeBit()进行标记为已使用(Set).
2. 然后使用TokenDown向下标记占用块(Set), level4占对应两个块(2bit), level3占4个, level2占8个, level1占16个, level0占32个;
3. TokenUp向上标记占用块(Set). level6栈1个块(1bit), level7占(1bit); 如果底层的两个块对应上层的同一个bit, 上层只是重复Set了一下, 没有影响.



**用户/内核内存分配 kalloc: 双向链表**

```c
struct malloc_header {
    size_t size;					// 代表实际给用户使用的块大小
    uint32_t free;					// bool类型 标志本块是否未分配
    uint16_t left;					// bool类型 标志与本块地址相邻的左边是否有被分割过的块
    uint16_t right;					// bool类型 标志与本块地址相邻的右边是否有被分割过的块
    malloc_header *next, *prev;
};

struct malloc_footer {
    size_t size;
};

// 实际堆管理中的一个管理单元结构如:
//   -----------------
//   | malloc_header |
//   | block         |
//   | malloc_footer |
//   -----------------
// 其中block就是用户指定要分配的多少bytes. block直接以地址形式返回, 没有任何地址保护!
```

以上是nymph堆管理中对每个内存块的管理结构, malloc_header就是一个带头节点的双向循环链表(实际把头节点作为链表结尾标记), 用户存放**可供分配(free)**的数据块. 由于内存具体分配是会有split(分割)和coalesce(合并)操作, 合并时需要知道左右相邻块的size信息, 所以**必须**有一个malloc_footer结构, 以便通过地址加减获得malloc_footer结构记录的size.

KMalloc()所做的就是: 

1. malloc_head 就是空闲数据块链表的头节点, 每次分配时从头节点开始向后遍历, 找到第一个可以满足大小是节点, 如果没有则通过伙伴内存管理器(buddy_allocator)分配适合大小的块, 插入链表尾, 下次循环就命中了. 
2. 找到合适节点后, 确认是合适块是否太大, 并且是否有必要分成两块. 如果有必要, 则会执行split操作, 此时就会标记malloc_header.left和malloc_header.right以便到时候进行coalesce操作. 分割后的链表中就多了一个空闲块, 原本的目标块就变小了
3. 将最终目标块从空闲链表中摘链, 定位到block地址处, 转型为void*返回即可.

KFree()就是以上的逆过程, 从free的block地址减去malloc_header结构大小, 就可以找到该目标块的节点信息, 对可以合并节点进行合并, 然后用头插法放回空闲链表



## slab分配设计

slab分配器是基于对象进行管理的，所谓的对象就是内核中的数据结构（例如：task_struct,file_struct 等）。相同类型的对象归为一类，每当要申请这样一个对象时，slab分配器就从一个slab列表中分配一个这样大小的单元出去，而当要释放时，将其重新保存在该列表中，而不是直接返回给伙伴系统，从而**避免内部碎片**。slab分配器并不丢弃已经分配的对象，而是释放并把它们保存在内存中。**slab分配对象时，会使用最近释放的对象的内存块，因此其驻留在cpu高速缓存中的概率会大大提高**。