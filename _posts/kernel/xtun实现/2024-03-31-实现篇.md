---
layout: post
title: 实现篇
category: kernel
typora-root-url: ../../..
---

总流程:

一个tap设备其实是利用字符设备驱动和网络设备驱动的结合体, xtun中xtun_chr.c实现了字符设备驱动, xtun_net.c实现了网络设备驱动. 接收数据包流程为:

```
 network
    |
    | packet recv
   \|/
xxx_interrupt() --> netif_rx()
 { eth0 }                  |
                           |
                           |
    .----------------------'
    |  raise irq
   \|/
softirq: net_rx_action() --> netif_receive_skb() -->    路由决策
                                                           |
                                                           |
    .------------------------------------------------------'
    |
   \|/
dev_queue_xmit(skb) --> tun_net_xmit()
 [skb->dev == tap0]     1. put skb into tun's skbqueue
                        2. wake up process(./tapip) waiting
                                    for /dev/net/tun (read/poll)
                             |
                             |
                            \|/
                         process (read/poll)
                       ( ./tapip            )
                       { usermode network stack }
```

发送数据包流程为:

```shell
 usermode
 network
 stack
   |
   | write
  \|/
/dev/net/tun --> tun_chr_aio_write() --> tun_get_user()
                                         1. copy data from usermode
                                         2. make skb(sending packet)
                                         3. netif_rx_ni
                                             |
                                             |
   .-----------------------------------------'
   |
  \|/
netif_rx(skb)
1. put packet into queue
2. raise softirq
   |
  \|/
softirq: net_rx_action() --> netif_receive_skb() --> handle_bridge()
                                                        { br0 }
                                                           |
                                                           |
    .------------------------------------------------------'
    |
   \|/
dev_queue_xmit(skb) --> {eth0 netdevice}_hard_xmit()
 [skb->dev == eth0]                       |
                                          |  packet send
                                         \|/
                                       network

```





### 第一步: 初始化步骤

比较简单, 主要就是初始化了相关的结构体, 参照snull即可. 

* struct net_device: 代表一个网络设备接口(网卡接口如eth0)
* struct net_device_ops: net_device中的成员, 指向几个必需的处理函数
* struct CXtunNetpriv: xtun驱动自行维护的数据结构, 作为net_device的priv成员

初始化struct net_device结构中使用到了ether_setup()该函数直接帮助设置以太网相关的必要信息. 另外**netdev_ops是必须设置**的, 不然`insmod xtun.ko`在register_netdev()时会导致内核oops, 主要是因为register_netdev()中会直接判断dev->netdev_ops->ndo_init, 然而此时netdev_ops为NULL!!!

运行:

```shell
insmod xtun.ko
#此时可以用`ip a`看到xtun接口了, 但是不能up它
rmmod xtun.ko
```

注意此时不能使用`ifconfig xtun up`等命令去启用它, 否则由于netdev_ops结构体中还没有设置.ndo_open, 为NULL, 则up该接口时调用了.ndo_open方法打开会导致系统卡死.



### 第二步: 填充操作方法模型

这一步, 我们为xtun添加了必要函数处理方法, 则适用于网卡的操作都可以对应到相应的驱动方法中.

运行:

```shell
insmod xtun.ko
ifconfig xtun 10.99.0.1/24 up
ifconfig xtun
ping -I xtun -c 4 10.99.0.2
ifconfig xtun
ifconfig xtun 0 down
rmmod xtun
```

这里可以通过日志查看每一步操作对应的xtun.ko中调用的方法. 在真正发送数据处, 会对tx_packets加一, 所以在`ifconfig xtun`中可以看到"TX packets"一栏有发包数量.

注意如果在XtunTx()之后没有对skb指针数据包结构调用dev_kfree_skb()正确的释放, **skb申请队列会占满, 那么后续发包无法申请sk_buff结构, 不能发包**. 如使用`ping -I xtun 10.99.0.2`一直发包, 后面就会报错:

```
ping: sendmsg: No buffer space available
```

所以这里第二步直接在XtunTx()中释放sk_buff.

另外有一点需要关注下: 不down掉xtun而直接rmmod xtun, 也是可以正常的. unregister_netdev()方法已经处理了这种情况.



### 第三步: 完善发包过程



### 第四步: 完善收包过程



### 第五步: 收发包测试与调优

上述基本功能写完了, 粗略的写一个简单的测试程序测试下, 主要是阻塞的从/dev/xtun读取数据, 然后直接写回:

```c
// filename: xtun_test.c
#include <stdio.h>
#include <stdlib.h>		/* exit */
#include <unistd.h>		/* read, write, close */
#include <sys/types.h>
#include <sys/stat.h>
#include <fcntl.h>		/* open */

static int xtun_alloc() {
	int fd, err;

	if( (fd = open("/dev/xtun", O_RDWR)) < 0 ) {
		perror("Cannot open TUN/TAP dev\n"
					"Make sure one exists with ");
		exit(1);
	}

	return fd;
}

int main() {
	char buf[2048];
	int ret, xtun_fd;
	
	xtun_fd = xtun_alloc();
	
	while (1) {
		if ((ret = read(xtun_fd, buf, 2048)) <= 0) {
			printf("read failed, ret:%d\n", ret);
			continue;
		}
		printf("read %d bytes from xtun.\n", ret);
		
		if ((ret = write(xtun_fd, buf, ret)) <= 0) {
			printf("write failed, ret:%d\n", ret);
			continue;
		}
		printf("write %d bytes to xtun.\n", ret);
	}
	
	close(xtun_fd);
	return 0;
}
```

测试使用ping指定从xtun网开接口发包, 此时测试程序会收到icmp包, 这里可以对数据包进行dump核对数据包完整性, 也可以使用tcpdump在xtun上抓包观察. 

```shell
ping -I xtun -c 4 10.99.0.2
```

由于xtun_test直接将数据包原样写回, 该数据包肯定不是合法回包, 会在传输过程中被某一步丢弃掉. 后续使用trace-cmd可以跟踪到丢包点.

**深入应用测试, 工具选择:**

上面的简单测试, 只是说明了从内核发包到xtun驱动再到用户态程序的过程是正常的, 而用户态程序使用xtun驱动发包给内核协议栈到底能不能正确处理就不知道了. 因此我们需要更多的工具进行测试, 这里用户态程序选择使用github上开源的基于tun/tap的用户态协议栈: level-ip和tapip, 这里选择相对简单但不是太完善(有bug)的level-ip. 调试工具选择systemtap + ftrace(trace-cmd)

总结下, 大体思路:

1. 使用lvl-ip, 设置好相应的iptables转发. 然后使用tools下的level-ip调用curl访问www.baidu.com, 调试工具跟踪调用tap过程

   ```shell
   # 首先, 确认iptables forward配置正确, tun设备已加载.
   # 开一个shell运行lvl-ip, 此时会默认构建tap0
   ./lvl-ip
   # 开一个shell跟踪tun.c中函数调用过程, 这里主要监控tun_get_user()
   trace-cmd -p function_graph -g tun_get_user
   # 开一个shell使用测试工具进行访问测试
   lvl_home=$(pwd)
   cd ${lvl_home}/tools && make
   cd ${lvl_home}/apps/curl && make
   cd ${lvl_home}/tools
   ./level-ip ../apps/curl/curl www.baidu.com 80
   # 访问完毕后可以使用ftrace看函数调用过程了
   trace-cmd report
   ```

   level-ip实际为shell脚本, 很简单, 就是执行程序前提前使用动态库liblevelip.so提供所需的相关符号, 将curl程序依赖于内核协议栈的系统调用导向了lvl-ip协议栈.

2. 修改level-ip默认使用xtun设备, 项目重建为lvlip_xxf, 即修改src/tuntap_if.c为

   ```c
   #include "syshead.h"
   #include "utils.h"
   #include "basic.h"
   
   static int tun_fd;
   static char* dev = "xtun";
   
   char *tapaddr = "10.0.0.5";
   char *taproute = "10.0.0.0/24";
   
   static int set_if_route(char *dev, char *cidr){
       return run_cmd("ip route add dev %s %s", dev, cidr);
   }
   
   static int set_if_address(char *dev, char *cidr){
       return run_cmd("ip address add dev %s local %s", dev, cidr);
   }
   
   static int set_if_up(char *dev){
       return run_cmd("ip link set dev %s up", dev);
   }
   
   
   int tun_read(char *buf, int len){
       return read(tun_fd, buf, len);
   }
   
   int tun_write(char *buf, int len){
       return write(tun_fd, buf, len);
   }
   
   void tun_init(){
       //dev = calloc(10, 1);
       //tun_fd = tun_alloc(dev);
   	if ((tun_fd = open("/dev/xtun", O_RDWR)) < 0) {
   		perror("open xtun failed.");
   		exit(1);
   	}
   
       if (set_if_up(dev) != 0) {
           print_err("ERROR when setting up if\n");
       }
   
       if (set_if_route(dev, taproute) != 0) {
           print_err("ERROR when setting route for if\n");
       }
   
       if (set_if_address(dev, tapaddr) != 0) {
           print_err("ERROR when setting addr for if\n");
       }
   }
   
   // xtun不会进行释放, 将由我们手动卸载模块才进行释放.
   void free_tun(){
   //    free(dev);
   }
   ```

   再重新走一遍上述的流程通过xtun设备访问网络.

   ```shell
   # 首先, 确认iptables forward配置正确, xtun设备已加载
   iptables -F
   iptables -F -t nat
   cd /path/to/lvlip_xxf
   ./xxf_setup.sh
   # 开一个shell运行lvl-ip, 此时会默认构建tap0
   cd /path/to/lvlip_xxf && make
   ./lvl-ip
   # 开一个shell跟踪tun.c中函数调用过程, 这里主要监控tun_net_xmit()
   trace-cmd -p function_graph -g XtunRx
   # 开一个shell使用测试工具进行访问测试
   lvl_home=$(pwd)
   cd ${lvl_home}/tools && make
   cd ${lvl_home}/apps/curl && make
   cd ${lvl_home}/tools
   ./level-ip ../apps/curl/curl www.baidu.com 80
   # 访问完毕后可以使用ftrace看函数调用过程了
   trace-cmd report
   ```

3. 如果出现了问题, 使用systemtap到具体的探测点打印数据进行分析即可.

**错误总结**:

(一) ftrace定位到arp_rcv(), 它下一步调用consume_skb(skb)就没下文了

注意这里使用systemtap手册中的示例程序dropwatch.stp并不会捕获到因consume_skb()导致的丢包. 

```shell
...
|      do_softirq() {
|        do_softirq.part.18() {
|          __do_softirq() {
|            net_rx_action() {
|              process_backlog() {
|                _raw_spin_lock();
|                __netif_receive_skb() {
|                  __netif_receive_skb_core() {
|                    arp_rcv() {
|                      consume_skb() {
|                        skb_release_all() {
|                          skb_release_head_state();
|                          skb_release_data() {
|                            skb_free_head() {
|                              __free_page_frag();
|                            }
|                          }
|                        }
|                        kfree_skbmem() {
|                          kmem_cache_free() {
|                            ___cache_free();
|                          }
|                        }
|                      }
|                    }
|                  }
|                }
|                _raw_spin_lock();
|              }
|            }
|            rcu_bh_qs();
|            __local_bh_enable();
|          }
|        }
|      }
...
```

这里起初以为是传入的skb包错误, 于是在集中注意力调试XtunRx()和tun_get_user()处理的不同点, 分析源码, 主要区别就是在于tun_alloc_skb()和skb_copy_datagram_from_iter()上, 其他的和vlan以及GSO相关的东西, 由于我并没有开启相关配置, 对我并没有影响. 

进一步分析tun_alloc_skb()发现它依赖于sk结构的队列, 考虑了分配时的多种情形. 这个是我所不想看到的, <u>底层的驱动为啥要负责考虑上层的结构带来的影响呢</u>? 由于对上层还不太了解, 这里就分析不下去了. 

这边分析skb_copy_datagram_from_iter()时, **由于其他程序调用的干扰无法用systemtap看清, 所以选择直接整个拷贝到Xtun项目中命名为Xtun_skb_copy(), 自定义添加打印信息, 配合systemtap看调用过程**. 但是skb_copy_datagram_from_iter()也依赖于tun_alloc_skb()这里设置的相关字段, 所以也分析不下去了.

这里没头绪了, 怎么办? 要去看整个上层协议栈了吗? 仔细想想, 其实问题的根源只是arp_rcv()中处理有异常, 那么我们直接分析arp_rcv()收到的包是怎样的, 并且处理过程又都是怎样的, 不就行了!!!

```bash
#!/usr/bin/env stap
# filename: arp_rcv_monitor.stp
probe begin { printf("Monitor begin\n"); }
probe end { printf("Monitor end\n"); }

probe kernel.statement("arp_rcv@net/ipv4/arp.c:*") {
	printf("%s\n", pp());
}

probe kernel.function("arp_rcv").call {
    printf("arp_rcv skb:\n%s\n\n", $skb$$);
}
```

执行之, 由于skb结构完全打印长度超限, 需要设置MAXSTRINGLEN, 参见`man stap`

```shell
# stap -DMAXSTRINGLEN=4096 arp_rcv_monitor.stp
kernel.statement("arp_rcv@./net/ipv4/arp.c:920")
kernel.statement("arp_rcv@./net/ipv4/arp.c:924")
kernel.statement("arp_rcv@./net/ipv4/arp.c:948")
kernel.statement("arp_rcv@./net/ipv4/arp.c:949")
kernel.statement("arp_rcv@./net/ipv4/arp.c:954")

...
```

看到这里收到的skb和使用tap0时收到的是一致的, 证明上面XtunRx对skb的处理并没有错误. 这里arp_rcv的执行过程看到在调用if判断不成功后直接goto consumeskb了:

```c
static int arp_rcv(struct sk_buff *skb, struct net_device *dev,
	struct packet_type *pt, struct net_device *orig_dev)
{
...
if (dev->flags & IFF_NOARP ||
	skb->pkt_type == PACKET_OTHERHOST ||
	skb->pkt_type == PACKET_LOOPBACK)
	goto consumeskb;
...
}
```

那么直接systemtap探测重新打印下dev->flags和skb->pkt_type的值, 对比下就可以发现问题了. 这边是因为这里参考snull的代码, 在XtunSetup()时设置了`dev->flags = IFF_NOARP`. 改正后arp_rcv()就正常了.

(二) arp收包正常了, 但是arp回包时, tcpdump抓到的包没有以太网头部, 被认为是错误包. lvl-ip收到后也会打印一条错误日志.

```shell
# tcpdump -XX -n -i xtun
11:12:22.483880 ARP, Request who-has 10.0.0.5 (ff:ff:ff:ff:ff:ff) tell 10.0.0.4, length 28
	0x0000:  ffff ffff ffff 000c 296d 5025 0806 0001  ........)mP%....
	0x0010:  0800 0604 0001 000c 296d 5025 0a00 0004  ........)mP%....
	0x0020:  ffff ffff ffff 0a00 0005                 ..........
11:12:22.483912 00:02:00:53:4e:55 > 00:01:08:00:06:04, ethertype Unknown (0x4c30), length 28: 
	0x0000:  0001 0800 0604 0002 0053 4e55 4c30 0a00  .........SNUL0..
	0x0010:  0005 000c 296d 5025 0a00 0004            ....)mP%....
	
# 对比tap0正常的应该是:
11:46:04.597655 ARP, Request who-has 10.0.0.4 tell 10.0.0.5, length 28
	0x0000:  ffff ffff ffff 5e69 f767 bdec 0806 0001  ......^i.g......
	0x0010:  0800 0604 0001 5e69 f767 bdec 0a00 0005  ......^i.g......
	0x0020:  0000 0000 0000 0a00 0004                 ..........
11:46:04.597734 ARP, Reply 10.0.0.4 is-at 00:0c:29:6d:50:25, length 28
	0x0000:  5e69 f767 bdec 000c 296d 5025 0806 0001  ^i.g....)mP%....
	0x0010:  0800 0604 0002 000c 296d 5025 0a00 0004  ........)mP%....
	0x0020:  5e69 f767 bdec 0a00 0005
```

使用systemtap在XtunTx()和tap_net_xmit()分别获取skb, 对比下差异.

```shell
#XtunTx 
skb: {<union>={<class>={.next=0x0, .prev=0xffff9c0cd60a6f00, <union>={.tstamp={.tv64=0}, .skb_mstamp={<union>={.v64=0, <class>={.stamp_us=0, .stamp_jiffies=0}}}}}, .rbnode={.__rb_parent_color=0, .rb_right=0xffff9c0cd60a6f00, .rb_left=0x0}}, <union>={.sk=0x0, .ip_defrag_offset=0}, .dev=0xffff9c0c808c7000, .cb="\034", ._skb_refdst=0, .destructor=0x0, .sp=0x0, .nfct=0x0, .nf_bridge=0x0, .len=28, .data_len=0, .mac_len=0, .hdr_len=0, .queue_mapping=0, .__cloned_offset="", .cloned=0, .nohdr=0, .fclone=0, .peeked=0, .head_frag=0, .xmit_more=0, .pfmemalloc=0, .headers_start=[0, ...], ...}

#tun_net_xmit 
skb: {<union>={<class>={.next=0x0, .prev=0xffff9c0cd878ee00, <union>={.tstamp={.tv64=0}, .skb_mstamp={<union>={.v64=0, <class>={.stamp_us=0, .stamp_jiffies=0}}}}}, .rbnode={.__rb_parent_color=0, .rb_right=0xffff9c0cd878ee00, .rb_left=0x0}}, <union>={.sk=0x0, .ip_defrag_offset=0}, .dev=0xffff9c0c80b9c000, .cb="*", ._skb_refdst=0, .destructor=0x0, .sp=0x0, .nfct=0x0, .nf_bridge=0x0, .len=42, .data_len=0, .mac_len=0, .hdr_len=0, .queue_mapping=0, .__cloned_offset="", .cloned=0, .nohdr=0, .fclone=0, .peeked=0, .head_frag=0, .xmit_more=0, .pfmemalloc=0, .headers_start=[0, ...], ...}
```

我们关注.len字段, 发现一开始上层调用xtun驱动注册的发包函数XtunTx时传入的包就是有问题的. 上面第(一)步已经确保收包是正常的了, 那么发包有问题应该是xtun网卡驱动部分在初始化设置时的配置问题, 它最主要的就是设置了一下net_device结构体. 对比下tun.c在tun_set_iff()对于dev的设置, 排除掉对于支持GSO和vlan的设置, 加上对比下linux3.2版本的tun.c, 这里一开始认为就剩下tun_net_init()中对于dev->priv_flags的设置了. **这是一个比较容易误导的点!!!**

```c
static void tun_net_init(struct net_device *dev)
{
    ...
    ether_setup(dev);
    dev->priv_flags &= ~IFF_TX_SKB_SHARING;
	...
}
```

但是网上也没有介绍它的作用, 代码注释说是用于传输时控制skb共享. 如果他要发挥作用, 则应该在dev_queue_xmit或之前进行判断. 但是全局搜索代码并没有发现相关的在数据包输出过程中进行IFF_TX_SKB_SHARING判断的地方. 测试下代码, 发现也没有效果, 证明不是这个问题!!!

随意按tun.c中的顺序调整了下dev->netdev_ops和dev->header_ops的设置放在前面, 这时竟然就成功了. 分析ether_setup()的操作, 原来是我自己把dev->header_ops置为空结构的原因, 导致填充头部的时候调用到了空函数T_T

想起是自己开始设计时为了更深入的理解每个关键结构, 故意弄的一个坑... (不过总归是理解了^_^)



### 六. 完善其他控制接口

