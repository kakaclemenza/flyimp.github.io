---

layout: post
title: 读核基础知识(基础数据结构等)
category: kernel
typora-root-url: ../../
---





注: 内核版本为linux-3.2.x

### 内核关键功能分布概览

```shell
.
├── 中断
│   └── softirq.c
├── 内存管理
│   ├── binfmt_elf.c
│   ├── fault.c
│   ├── memory.c
│   ├── mmap.c
│   ├── pgtable.h
│   ├── swapfile.c
│   ├── vmalloc.c
│   └── vmscan.c
├── 初始化
│   ├── arch-i386-bootsetup.S
│   ├── head.S
│   └── main.c
├── 多对称出处理
│   ├── semaphore.h
│   └── spinlock.h
├── 文件系统
│   ├── balloc.c
│   ├── ext2_fs.h
│   ├── ext2_fs_i.h
│   └── inode.c
├── 系统调用
│   ├── entry.S
│   ├── info.c
│   ├── sys.c
│   ├── time.c
│   └── traps.c
├── 网络
│   ├── dev.c
│   ├── isa-skeleton.c
│   └── netdevice.h
├── 虚拟文件系统
│   ├── fs.h
│   ├── open.c
│   ├── quota.h
│   ├── read_write.c
│   └── super.c
├── 设备管理
│   └── genhd.c
├── 进程管理
│   ├── capability.c
│   ├── capability.h
│   ├── exec.c
│   ├── exit.c
│   ├── fork.c
│   ├── sched.h
│   └── system.h
└── 进程间通信
    ├── kernel-signal.c
    ├── msg.c
    ├── pipe.c
    ├── sem.c
    ├── sem.h
    ├── shm.c
    └── signal.c
```





### 双向循环链表

该链表的基本结构很简单, 主要作用就是构造链, 为带头节点链表, 头节点不存放数据! 链表其他节点需要与具体的数据内容绑定, 才能成为有作用的链表

```c
// 链表基本结构
struct list_head {
    struct list_head *next, *prev;
};

// 与具体数据绑定
struct example {
    int data;
    list_head node;
};
```

既然与数据绑定了, 那么如何通过链表节点找到真正的数据体呢? linux中通过几个宏定义来获取.

```c
// include/linux/list.h
/**
 * list_entry - get the struct for this entry
 * @ptr:        the &struct list_head pointer.
 * @type:       the type of the struct this is embedded in.
 * @member:     the name of the list_struct within the struct.
 */
#define list_entry(ptr, type, member) \
        container_of(ptr, type, member)

// include/linux/kernel.h
// 其实就是取到了 MEMBER 相对于 TYPE 的偏移
#define offsetof(TYPE, MEMBER) ((size_t) &((TYPE *)0)->MEMBER)

/**
 * 这里typeof()是gcc的扩展，用于获取变量的类型;
 * __mptr变量作为中间变量, 不直接使用ptr主要是为了做类型检查
 */
#define container_of(ptr, type, member) ({                      \
        const typeof( ((type *)0)->member ) *__mptr = (ptr);    \
        (type *)( (char *)__mptr - offsetof(type,member) );})

// 例子: 获取上面 struct example 中的 data
struct exmaple item;
struct list_head* listp = &item.node;
// 下面就展示如何在已知链表节点(listp)和数据体结构(struct exmaple 和 node 两个命名)
// 情况下, 获取到内存中数据体指针
struct example *p = list_entry(listp, struct exmaple, node);
p->data;
```

另外就是对应的增删操作, 和遍历操作, 这里只介绍下一些可能比较难理解的, 其他的可以直接看源文件:

```c
/*** 创建链表 ***/
#define LIST_HEAD_INIT(name) { &(name), &(name) }
// 创建并初始化, 首尾节点都指向自身
#define LIST_HEAD(name) \
        struct list_head name = LIST_HEAD_INIT(name)
// 只进行初始化
static inline void INIT_LIST_HEAD(struct list_head *list)
{
        list->next = list;
        list->prev = list;
}

/*** 链表增加节点 ***/
tatic inline void __list_add(struct list_head *new, struct list_head *prev, struct list_head *next)
{
    next->prev = new;
    new->next = next;
    new->prev = prev;
    prev->next = new;
}
static inline void list_add(struct list_head *new, struct list_head *head)
{
    __list_add(new, head, head->next);
}

/*** 链表删除节点 ***/
static inline void __list_del(struct list_head *prev, struct list_head *next)
{
    next->prev = prev;
    prev->next = next;
}
// __list_del 把entry从链表中删除, 之后把entry链表指针复制成非空指针(如果使用会出现段错误)
static inline void list_del(struct list_head *entry)
{
    __list_del(entry->prev, entry->next);
    entry->prev = LIST_POISON1;
    entry->next = LIST_POISON2;
}

/*** 链表循环 ***/
// 都是从head->next开始的! 也就是带头节点链表, 头节点不存放数据, 这里 pos 每次存放链表节点指针
#define list_for_each(pos, head) \
        for (pos = (head)->next; pos != (head); pos = pos->next)
// 这里 pos 每次获得的则是数据体的指针!!! head依旧是链表头, member为链表节点在数据体结构中的命名
#define list_for_each_entry(pos, head, member)                          \
        for (pos = list_entry((head)->next, typeof(*pos), member);      \
             &pos->member != (head);    \
             pos = list_entry(pos->member.next, typeof(*pos), member))
```



### 哈希表

内核中的哈希表, 就是: **数组 + 哈希链表**; 数组没啥好说的, 哈希链表则是经过精心涉及的.

ref: https://blog.csdn.net/shanzhizi/article/details/8963332

### 哈希链表

哈希链表其实就是指通过**拉链法**实现的哈希表中的链表, 不过在linux下通常这种链表被特殊实现为哈希链表. 它的特点就是链表头节点只有一个指针, 指向链表首节点. 这样设计的好处就是, 在海量的**哈希表散列数组**中存储哈希链表的**表头**就能减少一半的空间消耗. 因为表头和节点的结构不同, 带来的操作上就与普通双向链表的不同处也就比较容易通过对比进行理解了, 这里就不细说了. 其结构如:

![内核哈希表结构](/img/kernel/kernel_hashtable.png)

```c
struct hlist_head {  
    struct hlist_node *first;  
};  

/**
 * 表头(hlist_head)和节点(hlist_node)的数据结构不同.
 * pprev是一个指针, 指向前一个节点的next指针. 那么就可以用相同的方式指向first, 这是一种巧妙设计!
 */
struct hlist_node {  
    struct hlist_node *next, **pprev;  
};
```

**哈希链表变种:**

```c
struct hlist_nulls_head {
    struct hlist_nulls_node *first;
};
struct hlist_nulls_node {
    struct hlist_nulls_node *next, **pprev;
};
```

哈希链表变种和标准哈希链表的区别是：链表的结束节点不是NULL。如果first或者next指针的最后一位为1，就说明遍历到链表尾部了。

Q：为什么可以根据节点指针的最后一位是否为1来判断链表是否结束？

A：因为在一个结构体中，其元素是按4字节(32位机器)或者8字节(64位机器)对齐的。所以有效的节点指针的最后一位总是为0。因此我们可以通过把节点指针的最后一位置为1，来作为结束标志。

**哈希链表遍历**

```c
#define hlist_for_each_entry(tpos, pos, head, member) \
	for (pos = (head)->first; \
	pos && ({ tpos = hlist_entry(pos, typeof(*tpos), member); 1;}); \
	pos = pos->next)
```

相比于list_for_each_entry, 这里多了一个tpos. 这**主要是因为哈希链表的头节点和其他节点结构不一样, 无法作为链表中数据体的成员**, 所以无法通过头节点去索引到数据体. 这样, hlist_for_each_entry中的**pos其实指向每次循环中的链表指针, tpos才是指向每次迭代中获得的数据体**.

其实换个命名方式会很显而易见容易理解....



### linux系统的引导流程



### ({}) 作用

内核中很多宏定义是利用这样的方法实现的. 其作用是获取{}内表达式的返回结果. 当然一般会在{}中定义临时变量, 最终返回临时变量的值.

### do {...} while(0) 作用


### capable()


### typeof()

### prefetch()

### DEFINE\_\* 定义

### 内核中的锁分类与作用
rtnl_lock()

rcu_assign_pointer() 赋值保护: 见kernel/notifier.c:30

### 锁掩码

### 禁用中断
`local_bh_disalbe()` 禁用软中断



### WARN_ON(), ERROR_ON()

### 柔性数组 char a[0];


### 内核栈

1. 读Linux内核以及相关的资料的时候，时刻要清醒地认识到它说的是内核态还是用户态的东西。
2. 一个用户态进程/线程在内核中都是用一个task_struct的实例描述的，这个有点类似设计模式里面的桥接模式(handle-body), 用户态看到的进程PID，线程TID都是handle, task_struct是body。
3. C语言书里面讲的堆、栈大部分都是用户态的概念，用户态的堆、栈对应用户进程虚拟地址空间里的一个区域，栈向下增长，堆用malloc分配，向上增长。
4. 用户空间的堆栈，在task_struct->mm->vm_area里面描述，都是属于进程虚拟地址空间的一个区域。
5.而内核态的栈在tsak_struct->stack里面描述，其底部是thread_info对象，thread_info可以用来快速获取task_struct对象。整个stack区域一般只有一个内存页(可配置)，32位机器也就是4KB。
6. 所以说，一个进程的内核栈，也是进程私有的，只是在task_struct->stack里面获取。
7. 内核态没有进程堆的概念，用kmalloc()分配内存，实际上是Linux内核统一管理的，一般用slab分配器，也就是一个内存缓存池，管理所有可以kmalloc()分配的内存。所以从原理上看，在Linux内核态，kmalloc分配的所有的内存，都是可以被所有运行在Linux内核态的task访问到的。

### 内核的一些命名特点

* EXPORT_DEFINE

  内核中使用该宏定义导出函数, 使得函数可以在外部进行调用.

* gfp: 

  gfp就是get free page的意思, 因为在kmalloc的内存分配函数中最终都会调用get_free_pages()来分配, 传入一个flags来控制获取空闲页的具体行为

  最常用的取值是GFP_KERNEL，因为最终都是调用get_free_pages来完成内存分配，所以这些flag基本都以GFP为前缀，我在Atheros驱动开发中，几乎都是使用这种内存分配方式，它表示内存分配是代表运行在内核空间的进程执行的，当空闲空间较少的时候，kmalloc会把当前**进程休眠**来等待空闲页。

  但有时候kmalloc要在进程上下文之外被调用，如中断处理、tasklet、内核定时器中，这时候current进程不能休眠，所以GFP_KERNEL也就不适用了，此时可以换用GFP_ATOMIC，内核会原子性地分配哪怕是最后一个空闲页面，如果真是空间不够用了，会**返回失败**。



### skbuff数据指针与操作 

skbuff中各关键成员及其含义如下图:

```shell
 low                                                                high
  +-------------------+----------------------+------------------------+
  |                   |                      |                        |
  +-------------------------------------------------------------------+
  ^  skb_headroom     ^        len           ^     skb_tailroom       ^
  |                   |                      |                        |
head                 data                   tail                     end
```

各常用操作的效果:

* skb_push(): data左移, skb_headroom减小, len增加
* skb_pull(): data右移, skb_headroom增大, len减小
* skb_trim(): tail左移, skb_tailroom减小, len增大
* skb_put(): tail右移, skb_tailroom增大, len减小



1. 可重入问题
2. 系统日志文件差别
3. modprobe/insmod的原理
4. 主设备号和从设备号
5. 驱动相关的三个内核数据结构: file_operations, file, inode
6. 等待队列 wait_queue 与非阻塞io的关系.



### 内核源码编译相关

完整的内核编译构建最好是参考官方文档: https://www.debian.org/doc/manuals/debian-kernel-handbook/ch-common-tasks.html

`make modules`会在内核源码目录下生成Module.symvers; 该文件后续被放在linux-headers**内核源码树**结构中, 最终安装到/lib/modules/$(uname -r)/build/Module.symvers, 主要记录着内核导出的各个符号(EXPORT_SYMBOL()导出)在本内核中的CRC校验值. 编译自己的模块时使用到内核导出符号(肯定会用到!), 就会获取/lib/modules/$(uname -r)/build/Module.symvers中的值, 编译进自己的模块中. insmod的时候会和当前运行内核进行匹配, 不匹配就会报错.

### GNU C和标准C的差别

参考`<宋宝华: linux设备驱动开发详解>::3.5`

**命名规范问题**: 如果是要并入内核源码的代码, 必须遵循linux内核编码规范, 否则不会被采纳.

### likely和unlikely

这两个虽然随内核版本更替有所变动, 但最终定义是像下面这样的:

```
//定义位于include/linux/compiler.h
#define likely(x) __builtin_expect(!!(x), 1)
#define unlikely(x) __builtin_expect(!!(x), 0)
```

__builtin_expect()是GNU C内建函数(见[GNU C和标准C的差别](#GNU C和标准C的差别)). likely和unlikely这两个宏只是为了**给编译器优化提供信息**, 其实不会改变程序逻辑:

* 使用likely(), 执行if后面的语句的机会更大
* 使用unlikely(),执行if后面的语句的机会更小

### 内核模块Makefile解析

编译模块的时候，你可以将模块放在代码树中，用Make modules的方式来编译你的模块，obj-$(CONFIG_EXT2) += ext2.o即可 
你也可以将模块相关文件目录放在代码树以外的位置，用如下的命令来编译模块： 
make -C < path to kernel src> M=$PWD modules 

-C指定代码树的位置，M=$PWD或M=’PWD’告诉kbuild回到当前目录来执行build操作

```makefile
# 以下编译适合于在内核代码树之外编译内核模块。
# 整个过程会导致本Makefile文件被加载执行两遍。
# 第一遍执行时，由于`KERNELRELEASE`没有被定义，所以先执行`else`下的逻辑。
# 此时由于make没有指定具体目标, 会选择第一个不以.开头的目标执行, 即modules
# `-C $(KERNEL_DIR)`指明跳转到内核源码目录下读取那里的Makefile；
# `M=$(CURDIR)`表明然后返回到当前目录继续读入当前的Makefile并执行之。此为第二遍执行。
# 第二遍执行时，此时从内核源码目录返回时，KERNELRELEASE已被被定义，
# kbuild也被启动去解析kbuild语法的语句，make将继续读取`if`中的逻辑。
# else之前的内容为kbuild语法的语句, 指明模块源码中各文件的依赖关系，以及要生成的目标模块名。

ifneq ($(KERNELRELEASE),)
    ccflags-y := -std=gnu99 -DENABLE_DEBUG
    scull-objs := main.o fops.o
    obj-m := scull.o
else
    KERNELDIR ?= /lib/modules/$(shell uname -r)/build
    PWD := $(shell pwd)

modules:
	$(MAKE) -C $(KERNELDIR) M=$(PWD) modules
endif

# .PHONY最主要的作用是将一个目标作为"参数", 即不会因当前目录下已经存在clean文件
# 就不执行clean构造了.
.PHONY: clean
clean:
	$(MAKE) -C $(KERNELDIR) M=$(PWD) clean
```

总的理解就是, 第一次在内核源码树外部执行make, 只是为了跳转到内核源码树中, 按内核源码树的Makefile的执行, 将scull目录视为内核的一个普通驱动的目录(M指定的$(PWD)), 构造内核模块scull.ko;

赋值方式: 

* = 递归展开变量的赋值方式

* := 简单扩展变量的赋值方式:  用这种方式定义的变量, 会在变量的定义点, 按照被引用的变量的当前值进行展开

* ?= 赋默认值, 如果没有初始化该变量, 就给它赋上默认值

* += 添加值: 

  变量从前没有被定义过, +=和=是一样的

  变量已经有定义的时候, +=就会按源变量选择立即扩展(:=)或延后递归展开(=)

### `__init`和`__exit`

参考`<ldd3>::第二章::初始化和关闭`



### goto只应在错误处理中使用



### owner字段和THIS_MODULE

THIS_MODULE指向当前的模块struct module结构, 和current相似, 它的作用是用来获取模块当前的状态. 在rmmod时会把当前模块置为MODULE_STATE_GOING状态, 确保不会卸载正在被使用中的模块. __this_module是在*.mod.c文件中定义的.

### 一个字符设备关键的结构



### 内核模块无法插入

* 

* no symbol version for module_layout

  这个错误说明内核虽然



### __ratelimit: 250 callbacks suppressed

表示内核阻止了N条syslog消息，这是因为系统重复的日志过多（频率过高），太快输出，被内核中的net_ratelimit()限制了syslog消息. 这个rate limit也是Linux为了避免DoS***的一种机制. 这个限制可以通过/proc/sys/kernel/printk_ratelimit和/proc/sys/kernel/printk_ratelimit_burst来调优. 在内核的网络代码中有自己的限制配置（逻辑相同，但是是独立的配置） /proc/sys/net/core/message_cost和/proc/sys/net/core/message_burst，默认配置也是5和10



### 用户空间到内核空间可以直接赋值吗?

看epoll_ctl()的系统调用代码, 内核空间对于epoll_event需要从用户空间拷贝到内核空间的函数栈中, 所以有这个疑问.

系统调用传参，跟函数传参是比较类似的，分为基础类型和内存块类型这两类。

* 对于基础类型，通过寄存器可以直接拷贝传递
* 对内存块类型，C语言没有语言类型上的支持，必须通过指针进行传递，然后再访问指针指向的内存空间

这里主要是因为对于结构体而言, 已经不是基本类型, 所以传递过程中使用到了指针(地址). 那么内核态处理这个指针首要任务就是检查其合法性.  关于合法性的几个问题:

1. buf 指针是不是一个合法地址
2. 如果buf 指针是一个合法地地，但是该buf指针的空间，内核还没有给它分配物理地址空间怎么办
3. 如果黑客故意将buf值写成一个精心构造的内核地址，那驱动需要往该buf拷贝数据时（通过是read操作），那不是将数据写到内核态了吗？那黑客就可以通过这个问题来修改内核代码，控制内核执行，达成目标。

对应的解决方案便是copy_from_user/copy_to_user所做的, 实现原理如下：

1. 如果buf空间属于内核态空间，直接返回出错，不处理（这是解决上述场景3）
2. copy_from_user/copy_to_user使用精心布置的访存汇编实现，并指这个汇编指令所在的地址全部登记起来（称为extable表）。运行时出现上述场景1)和2)，首先会发生缺页异常，进入内核do_page_fault流程；然后检查出错的PC地址是不是早已在extable登记好的，如果是，同表示该缺页异常是copy_from_user/copy_to_user函数产生的。最后才检查该地址是否为该进程的合法地址，如果是则分配物理页并处理，否则就是非法地址，把进程给杀死(发送sigsegv信号)。

ref: https://www.zhihu.com/question/19728793/answer/137768893



### 内核模块参数



## 虚机模拟终端触发

ldd3后面高级的设备驱动编程, 涉及到实际的硬件中断, 但是一方面限于物理条件无法实现, 另一方面自己不是硬件专业, 捣鼓起来成本太高; 所以有一种能使用虚拟机进行模拟的方法非常有帮助. 以下结合自己的实践记录下:

### 利用virtualbox串口

一. virtualbox虚机配置

serial ports -> Port1配置

* Port Number: COM1; 
* Port Mode: Host Pipe;		# 使用主机的**命名管道**
* 不勾选"Connect to existing pipe/socket"	# 这样virtualbox就会自动创建**命名管道**
* Path/Address: /home/xiaofeng/com_test

二. host主机使用minicom连接到/home/xiaofeng/com_test

1. 首先配置minicom, `vi /etc/minicom/minirc.dfl`

   ```
   pu port unix#/home/xiaofeng/com_test
   ```

2. 然后运行minicom, 就会自动连接到命名管道

三. virtualbox虚机连接到/dev/ttyS0(COM0驱动)

### /dev/ttyS0~4与自己实现的中断的关系

假设我们virtualbox虚拟机使用的串口是COM0, 那么虚拟机中会默认关联到/dev/ttyS0设备驱动.

此时如果insmod我们自己的驱动程序, 使用request_irq()注册了中断处理程序, 则只有自己实现的驱动程序可以获取host从COM0串口传过来的数据. 这表明中断的注册会进行覆盖.

但是如果卸载掉我们的驱动程序, 则又可以从/dev/ttyS0获取到数据了, 因为此时/dev/ttyS0驱动成了截获COM0中断的驱动.
